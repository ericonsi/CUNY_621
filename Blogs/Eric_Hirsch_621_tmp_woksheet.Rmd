---
title: "What’s So Great about Heteroskedasticity?"
author: "Eric Hirsch, CUNY 621"
date: "2/27/2022"
output: html_document
---

```{r setup, include=FALSE, warnings=FALSE, messages=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings=FALSE, messages=FALSE)

#devtools::install_github("ericonsi/EHData", force=TRUE)

library(lmtest)
library(dplyr)
library(MASS)
library(EHData)
library(gridExtra)
library(tidyverse)


```

```{r}


data(pulp, package="faraway")  

summary(pulp)

op <- options(contrasts=c("contr.sum", "contr.poly"))  
lmod <- aov(bright ~ operator, pulp)  
summary(lmod) 

```

```{r}

library(ggplot2)  
ggplot(pulp, aes(x=operator, y=bright))+geom_point(position = position_jitter(width=0.1, height=0.0)) 


mod1 <- lm(bright~operator, pulp)
summary(mod1)
plot(mod1)


library(lme4)  
mmod <- lmer(bright ~ 1+(1|operator), pulp)  
summary(mmod) 


```




```{r}
library(tidyverse)
dfx <- read.csv("D:\\RStudio\\CUNY_621\\AdRevenue.csv", head=TRUE)

dfx <- dfx %>% 
  dplyr::select(AdRevenue, Circulation) %>%
  filter(Circulation <= 6) %>%
  filter(!row_number() == 3)

summary(dfx)


```

We run a regression on ad revenue and circulation.  There is a high r-squared (.89), but the residual plot shows some patterning. Clearly there is heteroskedasticity here, and so we can’t trust our statistical inferences. A BP test leads us to reject the null hypothesis (that heteroskedasticity is not present).  So what can we do?</font>

```{r, warnings=FALSE, messages=FALSE}
library(lmtest)
dfx1 <- dfx %>%
  dplyr::select(AdRevenue, Circulation)

p <- lm( AdRevenue ~ Circulation, dfx1)
plot(p, which = c(1))

bptest(p)
```

<font size=3>One option is to choose some transformation on the dependent variable and hope it does the trick. Commonly this is the log, so we take the log of ad revenue, run the regression again, and this is what our residual plot looks like now:</font>

```{r warnings=FALSE, messages=FALSE}

model <- lm(AdRevenue ~ Circulation, dfx)
summary(model)

plot(model, which = c(1))
bptest(model)

wts <- 1 / lm(abs(model$residuals) ~ model$fitted.values)$fitted.values^2

wls_model <- lm(AdRevenue ~ Circulation, data = dfx, weights=wts)

summary(wls_model)
plot(wls_model, which = c(1))
bptest(wls_model)

```

<font size=3> It worked!  While there are similarities to the previous plot, the tight bunching at lower levels of fitted values is gone.  There are a few odd points at the lower left of the plot which throw off the median, and one or two outliers that give the appearance of heteroskedasticity, but in reality this distribution is a lot more random. Indeed, a Breusch-Pagan test does not allow us to reject the null hypothesis (that heteroskedasticity is not present). So with one simple move, we’ve solved our problem. And while management may not understand our "log" formula, at least we can deliver them a reliable model.  

But this alone doesn’t really address the patterning in the variance. Unless we understand *why* the log transformation is effective, it only problematizes it and buries it. 
\
\

#### 2. A Data-Driven Approach

<font size = 3>This time we start with the data. Here is a scatterplot of ad revenue and circulation:


```{r, warnings=FALSE, messages=FALSE}
library(EHData)
ggplot(dfx,  aes(Circulation, AdRevenue)) +
      geom_point(fill="navy", color="navy") +
      geom_smooth(method = "lm", color="red", fill="lightcoral") + EHData::EHTheme()
```

While heteroskedasticity is specifically a patterning of variance within the *residuals*, we can nonetheless see where some of that variance originates. The scatterplot shows that the relationship between revenue and circulation becomes increasingly less tightly coupled as circulation becomes larger.  It should be noted that __this pattern of variance is extremely common__, and so it would benefit us to know when and why it happens.  If this is a feature of our data and we discover that it  has meaning and/or consequences, we would want to communicate this with management.  There are many reasons why it may occur - here are just four: 

*	__*a percentage or other size effect:*__ as newspapers get larger, mathematically a 10% variation in ad revenue is going to be much larger for the bigger papers than for the smaller ones.  Thus, we often see this cone-shaped patterning of heteroskedasticity when there is a very large range of low to high values, and particluarly when a percentage increase in the independent variable leads to a percentage increase in the idependent variable.

*	__*a missing variable:*__  newspapers may have more revenue options as they get larger. For example, maybe smaller newspapers tend to be free of charge, while the larger ones can rely more on subscription fees, and therefore some have less incentive to pursue ad revenues aggressively.  Heteroskedasticity is a common sign of a missing variable.

*	__*an interaction effect:*__  the relationship between circulation and ad revenue may be different for small newspapers compared to large. For example, the market for large advertisers may be much more competitive, but also much more lucrative, than for smaller advertisers. When entities at small and large values face different conditions with different type of variance, you will see heteroskedasticity.  Sometimes the cone faces the other way than in this dataset - for example, the relationship between flight departure delays and arrival delays shows much more variance for small departure delays than for large. 

* __*a hidden grouping effect:*__ large papers in small markets may exhaust advertising opportunities quickly, while large newspapers in large markets may have increased advertising opportunities.

The fact that a log transformation eliminated the heteroskedasticity may suggest that a percentage effect is in play, but we would want to investigate that further before we reached that conclusion.  Without more information, we don't know whether our model is incomplete or not.  __*And if the issue is a mispecification of the model, it is  contraindicated to use a transformation to hide the impact of the missing effects.*__  In any case, the pattern of the variance tells us that the relationship between circulation and ad revenue is less tight as newspapers get larger, and management should be aware of this as it suggests that relying on ad revenue may be increasingly more rewarding, but also more risky.  Further, we can see from the scatterplot that no matter what the true standard error is, it is unlikely to negate the effect completely. We can’t say precisely how much ad revenue will increase with increase in circulation, but we can, in fact, be confident that it will increase, even without a reliable standard error.

So we could report to management:

*“Here is a handy formula with a bit of advanced math - we can give you a hand if you need to decipher it”,* 

or we could report:

*“We’ve given you a ballpark estimate, give or take, of the relationship between circulation and ad revenue.  We’re confident ad revenue will increase with circulation, but if you need more precision around the “give or take” part, we can provide that with a more complex formula.  However, there’s something else you should be aware of.  As we increase in size, the risk- reward of generating ad revenue through circulation is going to increase.  We don’t know if this is simply inherent in the relationship, or if larger companies begin to replace ad revenue with subscription revenue or if something else is at play. This is something we’d like to study and request budgeting to do so.   In any case, this phenomenon should be incorporated into any company risk management strategy.”*

I know I would prefer the second.

In sum, heteroskedasticity violates a fundamental assumption about variance for our regression and therefore invalidates inferences based on standard errors and p-values.  But the fact is, variance may also tell an important story. Sometimes heteroskedasticity invalidates our entire model, but perhaps sometimes it is our model.  After all, a model is just a simplified description of what is significant about our data, it isn't the regression itself.

A final note - a debate in data science, up there with the Frequentists vs. Baysians, is how to spell heteroskedasticity (or is it heteroscedasticity?). Because the “hetero” suffix is Greek, technically speaking the Greek spelling (with a k) is more correct. However, it does give the appearance that the writer doesn't know how to spell and just went at it phonetically. So as always, it depends on use case and personal preference. I like heteroskedasticity because I like the way it looks.
